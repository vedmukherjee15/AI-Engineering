{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98ffb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71d2921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0fb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-5-nano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fdef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Promptchain(TypedDict):\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da4fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: Promptchain) -> Promptchain:\n",
    "\n",
    "    title = state['title']\n",
    "\n",
    "    prompt = f\"Generate a detailed outline for a blog on the topic: {title}\"\n",
    "\n",
    "    outline = model.invoke(prompt).content\n",
    "\n",
    "    state['outline'] = outline\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611ed91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state: Promptchain) -> Promptchain:\n",
    "\n",
    "    outline = state['outline']\n",
    "    title = state['title']\n",
    "\n",
    "    prompt = f'Write a detailed blog on the title - {title} using the follwing outline \\n {outline}'\n",
    "\n",
    "    content = model.invoke(prompt).content\n",
    "\n",
    "    state['content'] = content\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029dcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph  = StateGraph(Promptchain)\n",
    "\n",
    "graph.add_node('Create_Outline', create_outline)\n",
    "graph.add_node('Create_Blog', create_blog)\n",
    "\n",
    "graph.add_edge(START, 'Create_Outline')\n",
    "graph.add_edge('Create_Outline', 'Create_Blog')\n",
    "graph.add_edge('Create_Blog', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0f7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Future of Artificial Intelligence', 'outline': 'Here is a detailed, ready-to-use outline you can adapt for a blog post or a multi-part series on The Future of Artificial Intelligence.\\n\\nTitle options (pick one or mix and match)\\n- The Future of Artificial Intelligence: Opportunities, Risks, and What Comes Next\\n- 2030 and Beyond: A Practical View of the Future of AI\\n- AI’s Next Horizon: Technologies, Societies, and Strategies for the Next Decade\\n- From Narrow AI to Broad Impact: How AI Will Shape Our World\\n- The AI Era: Scenarios, Sectors, and the Shape of Society\\n\\nPurpose and audience\\n- Purpose: Inform readers about likely trajectories in AI, what technologies and sectors to watch, and how individuals and organizations can prepare.\\n- Audience: General readers with interest in technology; business leaders; policy makers; students and researchers; non-experts seeking a realistic, balanced view.\\n\\nVoice, scope, and framing\\n- Tone: Clear, informed, balanced, with concrete examples and without alarmism.\\n- Framing: Present a spectrum of possible futures (optimistic, cautious, and critical), emphasize core uncertainties, and highlight practical actions.\\n- Scope: Core concepts, near-term developments (next 5–10 years), sector-specific impacts, governance and ethics, and personal/organizational takeaways.\\n\\nDetailed outline\\n\\n1) Introduction: Why the future of AI matters\\n- Hook: A short, vivid scenario (e.g., a physician-assisted diagnosis aided by AI competing in accuracy with specialists, or a smart city optimizing energy with AI).\\n- Define the topic: What counts as “AI” today (narrow AI, foundation models, multimodal systems) and what might not (illustrate the difference between narrow AI, general AI, and AGI without sensationalism).\\n- Thesis: AI will increasingly augment human capabilities and transform systems, but the outcomes depend on design choices, governance, and human values.\\n- Preview: What readers will learn about technology trends, sector impacts, risks, governance, and concrete steps.\\n\\n2) The current state and recent breakthroughs\\n- What we mean by “AI today”: foundation models, multimodal models, reinforcement learning, robotics, and automation.\\n- Key milestones (without overclaiming): notable improvements in natural language understanding, vision, robotics, and real-world deployment examples.\\n- Limitations today: data dependence, bias and fairness concerns, interpretability gaps, alignment and safety challenges, energy costs.\\n- What’s changing now: scale, accessibility, tooling, and ecosystem development (open-source models, developer platforms, AI as a service).\\n\\n3) Key forces shaping the future of AI\\n- Compute and data: growth in hardware efficiency, specialized AI accelerators, data collection and quality.\\n- Algorithms and architectures: progress in foundation models, multimodal reasoning, retrieval-augmented approaches, and human-in-the-loop learning.\\n- Democratization and adoption: accessibility of tools for small teams, startups, and individuals; enterprise integration.\\n- Safety, ethics, and governance: evolving frameworks for risk assessment, transparency, and accountability.\\n- Regulation and policy: potential regulatory trends, incentives, and international cooperation.\\n- Societal and workforce dynamics: job transitions, new roles, reskilling needs, and economic shifts.\\n\\n4) Sector-by-sector impacts (illustrate with concrete examples and rationales)\\n- Healthcare\\n  - Diagnostics, personalized medicine, drug discovery, operational efficiency, patient engagement.\\n  - Opportunities and risks (privacy, bias in medical data, clinical validation).\\n- Education and learning\\n  - Personalized tutoring, automated assessment, administrative automation, accessibility.\\n  - Risks (quality control, equity, overreliance on automated content).\\n- Work, economy, and workforce\\n  - Productivity tools, collaboration copilots, job displacement vs. job creation, needed skills.\\n  - New roles and industries emerging from AI capabilities.\\n- Transportation and logistics\\n  - Autonomous vehicles, optimized routing, supply-chain resilience, safety considerations.\\n- Energy and environment\\n  - Climate modeling, optimization of systems, green AI (efficiency-focused research).\\n- Manufacturing and product development\\n  - Predictive maintenance, quality control, design automation, rapid prototyping.\\n- Public sector, governance, and policy\\n  - Public services automation, data-driven policy, transparency tools, regulatory compliance.\\n- Security, safety, and defense\\n  - Threat detection, cybersecurity, risk management, and ethical constraints.\\n- Creative industries and media\\n  - Content generation, personalization, AI-assisted design, copyright and attribution issues.\\n- Science and research\\n  - Accelerated literature review, hypothesis generation, simulation, and collaboration across disciplines.\\n\\n5) Core technologies and architectural shifts that will shape the future\\n- Foundation models and large-scale learning\\n  - Capabilities, scaling laws, and governance considerations.\\n- Multimodal and embodied AI\\n  - Combining text, image, audio, and sensor data; implications for robotics and virtual environments.\\n- Human-in-the-loop and alignment\\n  - RLHF, preference modeling, safety layers, and controllability.\\n- Edge AI and pervasive computing\\n  - Running AI locally on devices for privacy and latency benefits; trade-offs with model size.\\n- Explainability, auditing, and transparency\\n  - Techniques, limitations, and how to communicate AI decisions to non-experts.\\n- Privacy-preserving and secure AI\\n  - Federated learning, differential privacy, and secure inference.\\n- Data governance and quality\\n  - Data provenance, data minimization, bias mitigation, and reproducibility.\\n- Energy efficiency and sustainability\\n  - Hardware-software co-design; greener training and inference; lifecycle accountability.\\n\\n6) Risks, ethics, and governance\\n- Safety and alignment: ensuring AI systems do what people intend, even in novel contexts.\\n- Bias, fairness, and discrimination: data, models, and deployment contexts; mitigation strategies.\\n- Privacy and surveillance concerns: data collection, consent, and user rights.\\n- Security and misuse: adversarial attacks, automated disinformation, weaponization risks.\\n- Accountability and responsibility: who is responsible for AI outcomes; governance mechanisms.\\n- Inequality and power dynamics: concentration of AI capabilities; implications for economies and democracies.\\n- Global coordination: avoiding a fragmented governance landscape; standards and interoperability.\\n\\n7) Scenarios and timelines: how the future might unfold\\n- Short-term (0-5 years): incremental improvements, broader adoption in business processes, stronger emphasis on safety and governance.\\n- Mid-term (5-10 years): more capable models, cross-domain integration, new regulatory regimes, growing impact on jobs and services.\\n- Long-term (10-20+ years): potential shifts toward more generalized capabilities, deeper human-AI collaboration, ongoing debates about AGI and societal design.\\n- Provide balanced scenarios: optimistic (humane-centric, productivity gains, equitable access), cautious (benefits tempered by risks and governance needs), and skeptical (slower progress, governance frictions, safety concerns).\\n- Include indicators for readers to watch (e.g., model capabilities, regulation milestones, public adoption rates).\\n\\n8) Implications for individuals, organizations, and policymakers\\n- Individuals: skills to develop (critical thinking, data literacy, AI governance awareness), lifelong learning mindset.\\n- Businesses and startups: strategic areas to invest in, risk management, partnerships, and ethical deployment.\\n- Policymakers and regulators: framework design (safety standards, accountability, data governance, consumer protection), international cooperation, funding for research and education.\\n- Researchers and educators: curriculum development, interdisciplinary collaboration, responsible research practices.\\n\\n9) Practical guidance: how to prepare and act\\n- For individuals:\\n  - Build fundamental AI literacy; learn about data, privacy, and bias.\\n  - Develop adaptability: data analysis, programming basics, critical thinking, collaboration with AI systems.\\n- For organizations:\\n  - Start with governance: create an AI ethics/review board, risk register, and deployment playbooks.\\n  - Focus on data strategy: data quality, provenance, privacy protections, and evaluation metrics.\\n  - Pilot thoughtfully: choose high-value, low-risk use cases first; establish success criteria and rollback plans.\\n- For educators and communities:\\n  - Integrate AI literacy into curricula; create community resources; support reskilling programs.\\n- For policymakers:\\n  - Prioritize transparency, safety standards, workforce transition supports, and international collaboration on norms.\\n\\n10) Case studies and expert voices (optional, if your format allows)\\n- Short, real-world examples of successful AI projects and the lessons learned.\\n- Summaries of expert opinions (quotes or paraphrased insights) from researchers, industry leaders, and ethicists.\\n- Quick takeaways from each case study to anchor theory in practice.\\n\\n11) Myths vs. realities sidebar (optional)\\n- Common myths (e.g., “AI will automatically create perfect jobs for everyone,” or “AGI is imminent”) and concise debunks.\\n- Realistic reframing of expectations and uncertainties.\\n\\n12) Glossary and a quick reference box (optional)\\n- Define key terms: artificial intelligence, machine learning, deep learning, foundation models, RL, supervised learning, reinforcement learning, AI safety, alignment, bias, explainability, edge computing, etc.\\n\\n13) Visuals and data ideas (to accompany the outline)\\n- A simple timeline showing milestones and plausible future check-ins (5, 10, 15 years).\\n- Sector impact grid: likelihood of disruption vs. potential impact by sector.\\n- Architecture diagram: data, models, training, deployment, and governance loop.\\n- Infographic on safety and governance layers (policy, technical controls, auditing).\\n- Sidebars with quick stats or case highlights (cite sources when you have them).\\n\\n14) Writing plan and word-count guidance (optional)\\n- If targeting 1,800–2,500 words:\\n  - Introduction: 150–250 words\\n  - 3–4 main sections (state of the art, forces shaping the future, sector impacts): 350–500 words each\\n  - Risks, governance, and ethics: 350–500 words\\n  - Scenarios and practical guidance: 300–400 words\\n  - Conclusion and call to action: 150–200 words\\n- If targeting a longer piece (3,000–5,000 words):\\n  - Expand each major section with deeper examples, mini-case studies, expert quotes, and a more detailed governance discussion.\\n\\nOptional modular formats (to reuse for a series)\\n- Series arc: treat each major sector (healthcare, education, work, public policy, etc.) as a separate post with a consistent structure: current state, future trends, sector-specific implications, and governance questions.\\n- Expert roundups: gather 4–6 perspectives in a single post, with a concise synthesis of where those views converge/diverge.\\n- “Future scenarios” installment: a dedicated piece outlining optimistic, cautious, and skeptical futures with scenario-planning insights.\\n\\nTips for a strong write-up\\n- Ground forecasts in trend lines rather than bold speculation; clearly label what is near-term vs. long-term.\\n- Use concrete, real-world examples to illustrate abstract ideas (e.g., a healthcare AI tool reducing diagnostic turnaround time, or a city using AI to optimize energy use).\\n- Balance opportunity with risk: acknowledge potential benefits while explicitly addressing privacy, safety, bias, and governance concerns.\\n- Include reader actions: give clear takeaways readers can implement in their personal or professional lives.\\n- Cite sources where possible to build credibility; consider linking to reports from reputable research centers, standards bodies, and regulatory agencies.\\n\\nWould you like me to tailor this outline to a specific target length (e.g., a 1,500-word post, a 2,500-word article, or a 5,000-word feature) or to a particular audience (business leaders, policymakers, general readers, students)? I can also provide a ready-to-use, section-by-section skeleton with suggested word counts and fill-in prompts.', 'content': 'The Future of Artificial Intelligence: Opportunities, Risks, and What Comes Next\\n\\nIntroduction: Why the future of AI matters\\n\\nImagine a city at dusk where AI orchestrates energy use, traffic flow, and emergency response in real time, while a physician consults an AI-powered diagnostic assistant that matches specialist accuracy in many rare cases. A student in a rural village accesses personalized tutoring, and a small business finally has access to tools previously reserved for large enterprises. This is not a single-scene fantasy but a glimpse of a broader trajectory: artificial intelligence is moving from narrow, task-specific systems to more capable tools that augment human decision-making across sectors. The question is not whether AI will become more important, but how we shape its development, governance, and integration into everyday life.\\n\\nWhat counts as AI today, and what might not\\n\\nToday’s AI encompasses several interlocking ideas. Narrow AI refers to systems designed for specific tasks—image recognition, language translation, or game playing. Foundation models are large-scale, general-purpose AI systems trained on broad data and capable of handling a range of tasks with little task-specific tuning. Multimodal AI can process and relate information across text, images, audio, and other data streams. Artificial general intelligence (AGI) is a long-horizon concept referring to systems with broad, flexible understanding comparable to human cognition. We are not yet at AGI, and credible forecasts suggest AGI remains uncertain over the coming decades. The practical reality today is a spectrum: powerful, data-driven tools that excel in defined domains and increasingly sit at the center of organizational and societal change.\\n\\nThesis: AI will increasingly augment human capabilities and transform systems, but outcomes depend on design choices, governance, and human values\\n\\nThe promise is clear: AI can unlock productivity, accelerate discovery, and improve accessibility and safety in many domains. The risks are real: biased outcomes, privacy challenges, safety gaps, and governance challenges in a rapidly evolving ecosystem. Our aim should be to cultivate the upside while building robust governance, resilient systems, and inclusive benefits. This blog presents a balanced view: the near-term trajectory (5–10 years), sector-specific implications, a map of core technologies, governance considerations, and practical steps for individuals, organizations, and policymakers.\\n\\nWhat you’ll learn\\n\\n- The current state of AI, including notable breakthroughs and their limits\\n- Key forces shaping AI’s future: compute, data, algorithms, adoption, safety, and regulation\\n- Sector-by-sector impacts with concrete examples\\n- Core technologies and architectural shifts underpinning future AI\\n- Ethical, safety, and governance risks, plus strategies to mitigate them\\n- Scenarios and timelines: optimistic, cautious, and skeptical futures with indicators\\n- Practical guidance for individuals, organizations, educators, and policymakers\\n- Optional case studies and expert voices to ground theory in practice\\n\\nThe current state and recent breakthroughs\\n\\nWhat AI looks like today\\n\\n- Foundation models and beyond: Large language models (LLMs) that can perform multi-turn conversations, generate text, reason across multiple steps, and adapt to new tasks with little or no task-specific data.\\n- Multimodal capabilities: Systems that understand and relate text, images, audio, and sometimes video, enabling more natural interactions and richer inferences.\\n- Reinforcement learning and robotics: Agents that learn from interaction with environments, improving performance in games, simulations, and real-world tasks.\\n- Real-world deployment: AI-powered tools in healthcare (imaging triage assistance, decision support, operational optimization), finance (risk assessment, anomaly detection), customer service (chatbots and agent assist), manufacturing (predictive maintenance), and logistics (routing optimization).\\n\\nLimitations we still confront\\n\\n- Data dependence and bias: Model outputs reflect the data they were trained on, which can embed biases and inaccuracies.\\n- Interpretability and alignment gaps: It can be hard to understand why a model made a decision, and aligning model behavior with human values remains challenging.\\n- Safety and reliability: Models can fail in unfamiliar contexts, generate plausible but incorrect content, or be misused.\\n- Energy costs and environmental footprint: Training and running large models consume substantial energy; efficiency improvements are a growing priority.\\n- Data governance and privacy: The data used to train models raises concerns about consent, ownership, and leakage of sensitive information.\\n\\nWhat’s changing now\\n\\n- Scale and accessibility: More organizations can access powerful tools through platforms, open-source models, and AI-as-a-service offerings, lowering barriers to entry.\\n- Tooling and ecosystems: Better frameworks, evaluation metrics, and governance tooling are helping teams build, test, and deploy AI more responsibly.\\n- Practical adoption: Early use cases are expanding beyond novelty into core business processes, education, healthcare workflows, and public services.\\n\\nKey forces shaping the future of AI\\n\\nCompute and data\\n\\n- Hardware advances and specialized accelerators are driving faster, cheaper AI; data quality and curation remain essential for reliable performance.\\n- The data lifecycle—collection, labeling, cleaning, and governance—will increasingly determine model quality and fairness.\\n\\nAlgorithms and architectures\\n\\n- Foundation models continue to evolve, with improvements in reasoning, planning, and multi-step problem solving.\\n- Multimodal reasoning and retrieval-augmented approaches help systems access external knowledge, improving accuracy and up-to-date performance.\\n- Human-in-the-loop learning and preference modeling will shape safer, more controllable AI.\\n\\nDemocratization and adoption\\n\\n- Access to powerful tools is widening to startups, small teams, and individual developers.\\n- Enterprises are integrating AI into workflows, decision support, and customer experiences, while seeking governance playbooks to manage risk.\\n\\nSafety, ethics, and governance\\n\\n- Emerging frameworks emphasize risk assessment, transparency, accountability, and safety controls at the design, deployment, and post-deployment stages.\\n- Auditing, red-teaming, and red-teaming-like evaluation will become standard practice to uncover failure modes.\\n\\nRegulation and policy\\n\\n- Governments are exploring standards for safety, privacy, data protection, accountability, and consumer protection in AI-enabled services.\\n- International cooperation will be critical to avoid fragmentation and enable interoperability, especially for cross-border data flows and safety norms.\\n\\nSocietal and workforce dynamics\\n\\n- AI is likely to reshape job roles, create new kinds of work, and require reskilling at scale.\\n- Economic effects will be uneven across geographies and industries, heightening the importance of inclusive policy design and social safety nets.\\n\\nSector-by-sector impacts (illustrative, with concrete examples)\\n\\nHealthcare\\n\\n- Diagnostics and decision support: AI-assisted imaging and interpretation can speed up reading times and improve consistency.\\n- Personalized medicine: AI helps tailor therapies based on patient data and research insights.\\n- Drug discovery and operational efficiency: AI speeds up screening and optimizes clinical workflows.\\n- Risks: privacy concerns, data bias in medical datasets, and the need for rigorous clinical validation.\\n\\nEducation and learning\\n\\n- Personalized tutoring: AI-driven tutors adapt to a student’s pace and style.\\n- Automated assessment and feedback: Scalable ways to provide timely input to learners.\\n- Accessibility and inclusion: Tools that aid learners with disabilities and language barriers.\\n- Risks: ensuring quality and preventing overreliance on automated content; digital equity concerns.\\n\\nWork, economy, and workforce\\n\\n- Productivity and collaboration: AI copilots assist with drafting, data analysis, scheduling, and brainstorming.\\n- Job displacement vs. job creation: Some routine tasks may fade, while new roles emerge around AI development, governance, and data stewardship.\\n- Skills emphasis: critical thinking, data literacy, AI governance, and cross-disciplinary collaboration become increasingly valuable.\\n\\nTransportation and logistics\\n\\n- Autonomous and assisted navigation: Transportation systems become more efficient and safer through AI-augmented decision making.\\n- Supply chain optimization: Real-time routing, inventory management, and demand forecasting improve resilience.\\n- Safety considerations: Clear regulatory frameworks and robust testing to manage risk.\\n\\nEnergy and environment\\n\\n- Grid optimization and demand response: AI helps balance supply and demand, reduce peak loads, and integrate renewables.\\n- Climate modeling and resilience: Higher-fidelity simulations inform policy and engineering.\\n- Green AI: Research into energy-efficient training and inference to reduce environmental impact.\\n\\nManufacturing and product development\\n\\n- Predictive maintenance and quality control: Reducing downtime and defects.\\n- Design automation and rapid prototyping: Accelerating product development cycles.\\n\\nPublic sector, governance, and policy\\n\\n- Service automation: Streamlining administrative processes and citizen services.\\n- Data-driven policymaking: Using AI to analyze outcomes and optimize programs.\\n- Transparency tools: Enhancing accountability and public trust through explainable AI and audit trails.\\n\\nSecurity, safety, and defense\\n\\n- Threat detection and cyber defense: AI-enabled monitoring and anomaly detection.\\n- Risk management: Improved situational awareness and decision support under pressure.\\n- Ethical constraints: Strong governance to prevent misuse and ensure alignment with international norms.\\n\\nCreative industries and media\\n\\n- Content generation and personalization: Tools for writing, art, music, and design tailored to audiences.\\n- Intellectual property considerations: Attribution, licensing, and monetization models in AI-assisted creation.\\n- Public reception: Balancing innovation with cultural and ethical norms.\\n\\nScience and research\\n\\n- Accelerated discovery: AI-assisted literature reviews, hypothesis generation, and simulation across disciplines.\\n- Collaboration: Cross-disciplinary AI-enabled collaboration accelerates progress.\\n\\nCore technologies and architectural shifts shaping the future\\n\\nFoundation models and large-scale learning\\n\\n- Capabilities and scaling: Larger models typically unlock broader capabilities but come with higher costs and governance complexity.\\n- Governance considerations: Data provenance, model stewardship, and release practices become central to responsible deployment.\\n\\nMultimodal and embodied AI\\n\\n- Integrating text, images, audio, and sensory data enables richer interactions and more capable robotic systems.\\n- Implications: More seamless human-AI collaboration, as well as new challenges in perception, safety, and control.\\n\\nHuman-in-the-loop and alignment\\n\\n- Preference modeling and safety layers: Systems better aligned with human values and better controllable in practice.\\n- RLHF and other alignment techniques will continue to evolve to address misalignment in diverse contexts.\\n\\nEdge AI and pervasive computing\\n\\n- Local inference on devices reduces latency and improves privacy but can constrain model size and capability.\\n- Hybrid approaches balance on-device inference with cloud-based updates and tooling.\\n\\nExplainability, auditing, and transparency\\n\\n- Techniques to interpret and communicate AI decisions to non-experts are advancing, but complete transparency for all model behaviors remains difficult.\\n- Organizations will increasingly require explainability as part of risk management and regulatory compliance.\\n\\nPrivacy-preserving and secure AI\\n\\n- Federated learning and differential privacy enable learning from data without exposing raw data.\\n- Secure inference and encryption techniques reduce the risk of data leakage in deployment.\\n\\nData governance and quality\\n\\n- Provenance, versioning, bias detection, and reproducibility become standard practice in AI workflows.\\n- Data minimization and ethical data sourcing gain emphasis to mitigate privacy and consent concerns.\\n\\nEnergy efficiency and sustainability\\n\\n- Hardware-software co-design and more efficient training methods reduce environmental impact.\\n- Lifecycle accountability becomes part of responsible AI practices, including end-of-life management for models.\\n\\nRisks, ethics, and governance\\n\\nSafety and alignment\\n\\n- The core risk is systems acting in ways that do not match human intent in novel situations.\\n- Practices: rigorous testing, safety constraints, human oversight in high-stakes settings, and continuous monitoring post-deployment.\\n\\nBias, fairness, and discrimination\\n\\n- Bias can emerge from data, model architectures, and deployment contexts.\\n- Mitigation: diverse data, fairness benchmarks, auditing, and ongoing oversight.\\n\\nPrivacy and surveillance concerns\\n\\n- Widespread data collection for training and operation raises concerns about consent, ownership, and control.\\n- Safeguards: robust consent mechanisms, privacy-preserving techniques, and strong data governance.\\n\\nSecurity and misuse\\n\\n- AI-enabled threats include automated disinformation, phishing, and novel cyberattack classes.\\n- Defenses: adversarial testing, rigorous security practices, and monitoring for misuse.\\n\\nAccountability and responsibility\\n\\n- Clear lines of responsibility for AI outcomes—developers, deployers, and operators—are essential.\\n- Governance mechanisms: internal ethics reviews, external audits, and transparent reporting.\\n\\nInequality and power dynamics\\n\\n- Unequal access to AI capabilities can widen economic and political disparities if not addressed.\\n- Policy tools: public investment, open access to fundamental research, education, and inclusive deployment strategies.\\n\\nGlobal coordination\\n\\n- Fragmentation in standards and norms can hinder interoperability and safety.\\n- Pathways: international norms, shared safety standards, and cooperative research initiatives.\\n\\nScenarios and timelines: how the future might unfold\\n\\nA balanced set of futures helps ground expectations and planning. Consider three archetypes—optimistic, cautious, and skeptical—each with milestones and indicators to watch.\\n\\nShort-term horizon (0–5 years)\\n\\n- Incremental improvements in model accuracy, reliability, and safety controls.\\n- Broader enterprise adoption of AI for routine decision support, automation of clerical tasks, and customer interactions.\\n- Strong emphasis on governance, risk management, and privacy protections.\\n- Indicators: regulatory actions in major jurisdictions; widespread use of explainability tooling; more standardized procurement and risk assessment for AI deployments.\\n\\nMid-term horizon (5–10 years)\\n\\n- More capable, cross-domain models with improved reasoning, planning, and collaboration with humans.\\n- Cross-sector integration, including AI-assisted clinical workflows, education platforms, and public services.\\n- New regulatory regimes and auditing frameworks; increased emphasis on workforce transition programs.\\n- Indicators: formal safety and accountability standards; measurable productivity gains across sectors; evidence of retraining programs scaling up.\\n\\nLong-term horizon (10–20+ years)\\n\\n- Potential for deeper generalization and more natural human-AI collaboration in complex tasks.\\n- Ongoing debates about AGI and societal design, with governance structures evolving to address global coordination and equity.\\n- Indicators: consensus on international safety norms; robust frameworks for AI-enabled governance; continuing dialogue about ethics and societal values.\\n\\nPractical guidance: how to prepare and act\\n\\nFor individuals\\n\\n- Build AI literacy: understand how data, models, and privacy interact; learn basics of data analysis and how to interpret AI outputs.\\n- Develop adaptability: cultivate skills that complement AI—critical thinking, problem framing, collaboration with AI systems, and lifelong learning.\\n- Focus on transferable skills: ethics, governance, data stewardship, and domain expertise where human judgment remains essential.\\n\\nFor organizations and startups\\n\\n- Start with governance: establish AI ethics or review boards, risk registers, and deployment playbooks with clear decision rights.\\n- Invest in data strategy: improve data quality, provenance, privacy protections, and evaluative metrics to monitor performance and fairness.\\n- Pilot thoughtfully: choose high-value, low-risk use cases to demonstrate ROI, with clear success criteria and rollback plans.\\n\\nFor educators and communities\\n\\n- Integrate AI literacy into curricula and training programs; build community resources to demystify AI and empower responsible use.\\n- Promote interdisciplinary collaboration: AI alongside ethics, law, social science, and domain-specific fields to address complex challenges.\\n\\nFor policymakers and regulators\\n\\n- Design safety and accountability standards that are adaptable to rapid innovation but protect public interests.\\n- Support workforce transition: funding for reskilling, inclusive access to AI-enabled benefits, and social safety nets where needed.\\n- Encourage international cooperation: shared norms, interoperability, and joint research initiatives to avoid regulatory fragmentation.\\n\\nCase studies and expert voices (illustrative)\\n\\n- Healthcare deployment: An AI-aided radiology workflow reduces diagnostic turnaround times in a regional hospital network, freeing radiologists to focus on complex cases while maintaining patient safety through human oversight and ongoing validation.\\n- Education technology: An adaptive learning platform uses AI to tailor content to individual students, while teachers retain the ultimate responsibility for pedagogy and assessment; the system frees teachers to focus on mentorship and higher-order thinking tasks.\\n- Public sector application: A city uses AI for energy optimization in buildings, traffic signal timing, and predictive maintenance of critical infrastructure, achieving measurable efficiency gains and improved resilience.\\n\\nMyths vs. realities sidebar\\n\\n- Myth: AGI is imminent and will replace human labor across all sectors soon.\\n  Reality: AGI remains speculative on long timelines; near-term AI augments many tasks but does not universally replace human labor. Reasoned governance and education are essential to mitigate disruption.\\n- Myth: AI will automatically create perfect jobs for everyone.\\n  Reality: The transition will involve job shifts and new roles; proactive reskilling and social supports are critical to maximizing opportunities and minimizing harm.\\n- Myth: Privacy and safety concerns can be addressed after deployment.\\n  Reality: Proactive design, governance, and ongoing auditing are essential. Waiting until after deployment increases risk and costs.\\n\\nGlossary and quick references\\n\\n- AI: Artificial intelligence; systems capable of performing tasks that typically require human intelligence.\\n- ML: Machine learning; algorithms that learn patterns from data.\\n- DL: Deep learning; neural networks with multiple layers that excel at perception tasks.\\n- Foundation models: Large, general-purpose AI models trained on broad data, adaptable to many tasks.\\n- RLHF: Reinforcement learning from human feedback; a method to align models with human preferences.\\n- Multimodal AI: Systems that process and relate information across multiple data types (text, image, audio, etc.).\\n- Edge AI: Running AI computations on local devices rather than in the cloud.\\n- Federated learning: A privacy-preserving approach where models learn from data on multiple devices without exchanging raw data.\\n- Explainability: Techniques to clarify why a model produced a given result.\\n- Governance: The set of processes, policies, and controls that ensure AI is developed and used responsibly.\\n\\nVisuals and data ideas to support the piece\\n\\n- Timeline: Milestones for model capabilities, regulatory actions, and adoption curves over the next 5, 10, and 15 years.\\n- Sector impact grid: Likelihood of disruption vs. potential impact by sector (e.g., healthcare, education, manufacturing, public sector).\\n- Architecture diagram: Data → models → training → deployment → governance loop, highlighting feedback and oversight.\\n- Safety and governance infographic: Layers of governance, including policy, technical controls, and auditing processes.\\n- Quick stat boxes: Short, cited data points on adoption rates, investment levels, or efficiency gains from AI deployments.\\n\\nWriting plan and length guidance (for reference)\\n\\n- A 2,500–3,000-word post can cover the outlines above with depth, including a couple of short case studies and a robust governance discussion.\\n- If you want a longer feature (3,500–5,000 words), you can expand each major section with more case studies, expert quotes, and a deeper dive into governance frameworks and international perspectives.\\n\\nWould you like me to tailor this piece to a specific target length or audience?\\n\\n- Target length: 1,500 words, 2,500 words, or 5,000 words?\\n- Target audience: general readers, business leaders, policymakers, students, or researchers?\\n- Any preferred emphasis (e.g., more on governance, more on sector-specific cases, more on practical takeaways for individuals)?\\n\\nIf you’d like, I can deliver a ready-to-publish, section-by-section draft tailored to your length and audience, including fill-in prompts and a concise bibliography of credible sources you can cite.'}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {'title' : 'The Future of Artificial Intelligence'}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "\n",
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
